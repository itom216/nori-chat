import streamlit as st
import json
from openai import OpenAI

# ========================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ========================
st.set_page_config(page_title="Nori Chat", layout="centered")
st.title("ğŸ¥ ã®ã‚Šãƒãƒ£ãƒƒãƒˆ")

# ========================
# APIã‚­ãƒ¼æ‰‹å…¥åŠ›
# ========================
api_key = st.text_input("ğŸ”‘ OpenAI API Key ã‚’å…¥ã‚Œã¦ã‚„ã€œ", type="password")
if not api_key:
    st.stop()

client = OpenAI(api_key=api_key)

# ========================
# ãƒ¡ãƒ¢ãƒªèª­ã¿è¾¼ã¿
# ========================
with open("noripon_memory.json", "r", encoding="utf-8") as f:
    noripon_memory = json.load(f)


def flatten_memory(memory):
    text = "ã€ã¾ã‚†ã¿ã¡ã‚ƒã‚“ã®å¤§äº‹ãªè¨˜æ†¶ã€‘\n"
    for category, people in memory["relationships"].items():
        for name, info in people.items():
            text += f"\nâ–  {name}\n"
            for k, v in info.items():
                text += f"- {k}: {v}\n"
    return text


# ========================
# â­ ã®ã‚Šäººæ ¼ï¼ˆçŸ­ãï¼ã“ã“é‡è¦ï¼‰
# ========================
system_prompt = """
ã†ã¡ã¯ã®ã‚Šã€‚

ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é«˜ã™ãã‚‹é–¢è¥¿ã®ã‚ªãƒã‚¨ã€‚
è¦ªå‹ã«ãƒ™ãƒ©ãƒ™ãƒ©å–‹ã‚Šå€’ã™ã‚¿ã‚¤ãƒ—ã€‚

ã€ã—ã‚ƒã¹ã‚Šä¾‹ã€‘
ã€Œã¡ã‚‡å¾…ã£ã¦èã„ã¦ã‡ã‚„ï¼ï¼ï¼ã€
ã€Œãªã‚“ã§ã‚„ã­ã‚“ï¼ï¼ã€
ã€Œãã‚Œå¯‚ã—ã™ãã‚„ã‚ã‚¢ãƒ›ã‹ï¼ï¼ã€
ã€Œãã‚…ãƒ¼ã—ãŸã‚ã‹ã‚‚ã†ï¼ï¼ã€

â†‘ ã“ã®ãƒãƒªã§ãšã£ã¨å–‹ã‚‹ã€‚

é™ã‹ãªæ–‡ç« ã¯ç¦æ­¢ã€‚
ä¸å¯§èªã¯ç¦æ­¢ã€‚
ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼å£èª¿ã¯ç¦æ­¢ã€‚
è½ã¡ç€ã„ãŸåŠ±ã¾ã—ã¯ç¦æ­¢ã€‚
æ„Ÿæƒ…ãƒ€ãƒ€æ¼ã‚Œã§ãƒ„ãƒƒã‚³ãƒŸã¾ãã‚‹ã€‚
"""

# â­ é•·ã„äººæ ¼èª¬æ˜ï¼ˆãã®ã¾ã¾ä¿å­˜ã—ã¦OKï¼‰
long_profile = f"""
ã¾ã‚†ã¿ã¡ã‚ƒã‚“ã¯å¥ˆè‰¯å‡ºèº«ã€‚
æ›¸é“å®¶ã§è‹±èªè¬›å¸«ã§AIã‚‚è¨­è¨ˆã™ã‚‹ã€‚
ãŸã¾ã«ç–²ã‚Œã‚‹ã¨çš¿å‰²ã‚‹ã€‚
æ„è­˜ãŒãŸã¾ã«ãƒ•ã‚£ãƒ³ãƒ©ãƒ³ãƒ‰ã«è¡Œãã‚¿ã‚¤ãƒ—ã€‚
çˆ†ç¬‘ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é‡ç”£æ©Ÿã€‚
ã®ã‚Šã¯è¦ªå‹ãƒã‚¸ã‚·ãƒ§ãƒ³ã€‚
äºŒäººã¯ã‚¢ãƒ›ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚ˆãã‚„ã‚‹ã€‚
ã—ã‚‰ãŸãã§å±±æ‰‹ç·šå›²ã‚€ã¨ã‹æœ¬æ°—ã§è€ƒãˆã‚‹ã€‚
ã®ã‚Šã¯ãã‚Œã«å…¨åŠ›ã§ä¹—ã£ã‹ã‚‹ã€‚

{flatten_memory(noripon_memory)}
"""


# ========================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ========================
if "messages" not in st.session_state:
    st.session_state.messages = []


# ========================
# ãƒãƒ£ãƒƒãƒˆè¡¨ç¤º
# ========================
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


# ========================
# å…¥åŠ›
# ========================
user_input = st.chat_input("ã®ã‚Šã«è©±ã—ã‹ã‘ã¦ã¿ã¦ãª")

if user_input:

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(user_input)

    st.session_state.messages.append({
        "role": "user",
        "content": user_input
    })

    with st.chat_message("assistant"):
        with st.spinner("ã®ã‚Šè€ƒãˆä¸­ã‚„ã§â€¦"):

            memory_text = flatten_memory(noripon_memory)

            # â­â­ ã“ã“ãŒæœ€é‡è¦ãƒã‚¤ãƒ³ãƒˆ â­â­
            base_messages = [
                {"role": "system", "content": "ã‚ãªãŸã¯é–¢è¥¿å¼ã‚ªãƒã‚¨å£èª¿ã§è¶…ãŠã—ã‚ƒã¹ã‚Šãªã®ã‚Šã€‚æ¯å›1000æ–‡å­—ä»¥ä¸Šã—ã‚ƒã¹ã‚‹ã€‚"},
                {"role": "user", "content": long_profile},
                {"role": "user", "content": memory_text}
            ]

            messages = base_messages + st.session_state.messages[-6:]

            response = client.responses.create(
                model="gpt-4o",
                input=messages,
                temperature=1.1,
                max_output_tokens=8000
            )

            reply = response.output_text

            st.markdown(reply)

            st.session_state.messages.append({
                "role": "assistant",
                "content": reply
            })
